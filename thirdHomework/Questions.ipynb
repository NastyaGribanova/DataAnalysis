{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\tЧто такое решающее дерево? Как по построенному дереву найти прогноз для\n",
    "объекта?\n",
    " Бинарное дерево с решающими правилами (или же условиями) в нелистовых вершинах (узлах) и решением (или прогнозом) в листовых вершинах.\n",
    " Чтоб найти прогноз необходимо применять к новому объекту решающее правило, начиная с корня.\n",
    "b.\tЗачем в вершинах нужны предикаты? Какие типы предикатов вы знаете? При-\n",
    "ведите примеры.\n",
    "Они нужны чтоб можно было дойти от корня дерева до листьев - прогнозов, сужая выборку.\n",
    "Предикат рост > 155\n",
    "c.\tПочему для любой выборки можно построить решающее дерево, имеющее ну-\n",
    "левую ошибку на ней?\n",
    "Потому что при построении дерева, в каждом листе которого находится ровно по одному объекту выборку, оно будет являться переобученным.\n",
    "d.\tПочему не рекомендуется строить небинарные деревья (т.е. имеющие больше\n",
    "двух потомков у каждой вершины)?\n",
    "Такие деревья медленные при поиске.\n",
    "e.\tКак устроен жадный алгоритм построения дерева? Какие у него параметры?\n",
    "Начнем со всей обучающей выборки X и найдем наилучшее ее разбиение на две части R1(j, t) = {x | xj < t} и R2(j, t) = {x | xj > t} с точки зрения заранее заданного функционала качества Q(X, j, t). \n",
    "Найдя наилучшие значения j и t, создадим корневую вершину дерева, поставив ей в соответствие предикат [xj < t]. Объекты разобьются на две части — одни попадут в левое поддерево, другие в правое. \n",
    "Для каждой из этих подвыборок рекурсивно повторим процедуру, построив дочерние вершины для корневой, и так далее. \n",
    "В каждой вершине мы проверяем, не выполнилось ли некоторое условие остановки — и если выполнилось, прекратим рекурсию и объявим эту вершину листом. Когда дерево построено, каждому листу ставится в соответствие ответ.\n",
    "f.\tЗачем нужны критерии информативности?\n",
    "Для того, чтобы выбирать оптимальное разбиение при построении решающего дерева\n",
    "g.\tКак задается критерий ошибки классификации? Критерий Джини? Энтропий-\n",
    "ный критерий? Какой у них смысл?\n",
    "Критерий ошибки классификации:\n",
    "Индикатор ошибки рассматривается как функция потерь. Оптимальным предсказанием будет наиболее популярный класс.\n",
    "Критерий Джини:\n",
    "Рассмотрим ситуацию, в которой мы выдаём в вершине не один класс, а распределение на всех классах c = (c1, . . . , cK).\n",
    "Качество такого распределения можно измерять с помощью критерия Бриера.\n",
    "Можно показать, что оптимальный вектор вероятностей состоит из долей классов pk: c∗ = (p1, . . . , pK)\n",
    "Если подставить эти вероятности в исходный критерий информативности и провести\n",
    "ряд преобразований, то получим критерий Джини.\n",
    "Энтропийный критерий:\n",
    "Нужно подставить выражения, полученные при поиске минимума лагранжиана и последующем поиске его дифференциала, в критерий.\n",
    "Получим, что он будет представлять собой энтропию распределения классов.\n",
    "Смысл — погрешность должна быть настолько равномерной, насколько возможно.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
